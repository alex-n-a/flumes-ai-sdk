# Flumes AI Memory SDK (Early Access)
**Flumes** is building a unified memory infrastructure for AI applications. This SDK is the starting point for developers who want to integrate scalable, cost-optimized memory into their LLM agents and workflows.

> ⚠️ Currently in early access. Request access: [https://flumes.ai](https://flumes.ai)

---

## 🧠 What is Flumes?

Modern AI agents need memory not just retrieval. Flumes provides:

- 🔄 **Persistent memory** for long-running agents
- 💡 **Hot/cold memory management** to optimize cost and speed
- 🧰 A clean, language-agnostic **Memory API**
- 📉 Built-in support for **token usage reduction**

Flumes is designed to plug into any AI stack, including OpenAI, LangChain, LlamaIndex, and custom pipelines.

---

## 🚀 Use Cases

- Chatbot memory persistence (user history, preferences)
- Compression and summarization of long conversations
- LLM cost control via intelligent memory pruning
- Unified memory store across agents and tools

---

## 📦 SDK Components (coming soon)

This SDK will include:

- `flumes-client`: Lightweight API wrapper for interacting with the Flumes Memory API
- `memory-events`: Example schema for memory events (store, retrieve, summarize)
- Sample projects & templates

---

## 📄 Docs & Architecture

For an overview of the memory model and architecture, see:

👉 [https://flumes.ai/building-a-memory-stack-what-we-learned-designing-flumes](https://www.flumes.ai/blog/building-a-memory-stack-what-we-learned-designing-flumes))

---

## 🧪 Status

We are currently working with a small group of alpha testers. If you’re building something that needs memory, we’d love to talk.

📬 [Request early access](https://flumes.ai)

---

## 👥 Community

While we’re in stealth, we’re selectively onboarding teams who need memory infra.

Want to explore fit? Email: `early@flumes.ai`

---

## License

MIT — Use at your own risk. Contributions welcome once SDK is public.
