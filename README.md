# Flumes AI Memory SDK (Early Access)
**Flumes** is building a unified memory infrastructure for AI applications. This SDK is the starting point for developers who want to integrate scalable, cost-optimized memory into their LLM agents and workflows.

> âš ï¸ Currently in early access. Request access: [https://flumes.ai](https://flumes.ai)

---

## ğŸ§  What is Flumes?

Modern AI agents need memory not just retrieval. Flumes provides:

- ğŸ”„ **Persistent memory** for long-running agents
- ğŸ’¡ **Hot/cold memory management** to optimize cost and speed
- ğŸ§° A clean, language-agnostic **Memory API**
- ğŸ“‰ Built-in support for **token usage reduction**

Flumes is designed to plug into any AI stack, including OpenAI, LangChain, LlamaIndex, and custom pipelines.

---

## ğŸš€ Use Cases

- Chatbot memory persistence (user history, preferences)
- Compression and summarization of long conversations
- LLM cost control via intelligent memory pruning
- Unified memory store across agents and tools

---

## ğŸ“¦ SDK Components (coming soon)

This SDK will include:

- `flumes-client`: Lightweight API wrapper for interacting with the Flumes Memory API
- `memory-events`: Example schema for memory events (store, retrieve, summarize)
- Sample projects & templates

---

## ğŸ“„ Docs & Architecture

For an overview of the memory model and architecture, see:

ğŸ‘‰ [https://flumes.ai/building-a-memory-stack-what-we-learned-designing-flumes](https://www.flumes.ai/blog/building-a-memory-stack-what-we-learned-designing-flumes))

---

## ğŸ§ª Status

We are currently working with a small group of alpha testers. If youâ€™re building something that needs memory, weâ€™d love to talk.

ğŸ“¬ [Request early access](https://flumes.ai)

---

## ğŸ‘¥ Community

While weâ€™re in stealth, weâ€™re selectively onboarding teams who need memory infra.

Want to explore fit? Email: `early@flumes.ai`

---

## License

MIT â€” Use at your own risk. Contributions welcome once SDK is public.
