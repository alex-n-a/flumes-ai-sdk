{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Q11-p0PgCCH"
      },
      "source": [
        "# Flumes: Give your AI a memory üöÄ\n",
        "\n",
        "In just a few cells, you‚Äôll give an agent long-term memory it can **store, search, and summarize** ‚Äî without duct-taping vector DBs or hacking together RAG code.\n",
        "\n",
        "This notebook walks you through the basics:\n",
        "1. **Install** the SDK\n",
        "2. **Store** a dense, real-world message ‚Üí watch Flumes extract structured facts & events\n",
        "3. **Retrieve** those memories to answer a new question\n",
        "\n",
        "---\n",
        "\n",
        "## Why Flumes is different\n",
        "\n",
        "- **One call, many jobs** ‚Üí extract, store, and assemble context in a single request\n",
        "- **Smart token budgeting** ‚Üí predictable caps so prompts don‚Äôt blow up costs\n",
        "- **Entity-first** ‚Üí memories tied to real users/entities, not just text chunks\n",
        "- **Human-like retrieval** ‚Üí balances facts, recency, and graph links out of the box\n",
        "\n",
        "---\n",
        "\n",
        "‚ö° **Quick start**\n",
        "You only need your Flumes API key.\n",
        "The base URL is already built in:  https://api.flumes.ai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3dTYcQXRgCCI"
      },
      "outputs": [],
      "source": [
        "# Paste your API key here or set FLUMES_API_KEY in your environment\n",
        "import os\n",
        "API_KEY = os.getenv(\"FLUMES_API_KEY\", \"your-api-key\")\n",
        "if API_KEY == \"your-api-key\":\n",
        "    print(\"‚ö†Ô∏è Set FLUMES_API_KEY or edit API_KEY above before running the rest.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yx6eVo38gCCJ"
      },
      "outputs": [],
      "source": [
        "# Install the SDK (one-time in Colab/local)\n",
        "%pip install -q openai #Only needed for the advanced agent example\n",
        "%pip install -q flumes-ai\n",
        "\n",
        "print(\"Installed flumes-ai\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SL1CJNPBgCCJ"
      },
      "outputs": [],
      "source": [
        "# Initialize the client (entity-first)\n",
        "from flumes import MemoryClient\n",
        "\n",
        "client = MemoryClient(api_key=API_KEY, agent_id=\"onboarding-bot\")\n",
        "entity_id = \"user_demo_001\"\n",
        "\n",
        "print(\"Client ready ‚Üí entity:\", entity_id)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p94OMZgxgCCJ"
      },
      "outputs": [],
      "source": [
        "# Step 1: Add a rich message (Flumes will extract structured facts/events)\n",
        "# This text is intentionally dense so the graph has plenty to show.\n",
        "\n",
        "u = client.for_entity(entity_id)\n",
        "\n",
        "rich_message = (\n",
        "    \"I'm Alice Parker, living in Paris since 2023. I usually travel with my brother Ben. \"\n",
        "    \"For work, I'm a product manager at Nova Labs. I prefer museums over nightlife and \"\n",
        "    \"love quiet wine bars in the Latin Quarter. My favorite artists are Monet and Van Gogh. \"\n",
        "    \"I'm training for a half-marathon; my pace is around 5:30/km. Budget for trips is about ‚Ç¨1200. \"\n",
        "    \"I have a gluten allergy and avoid crowded places on weekends. The last hotel I loved was Hotel Lumi√®re \"\n",
        "    \"near Jardin du Luxembourg; I rated it 5/5 in May 2025. I'm planning a 3-day getaway to Lyon next month, \"\n",
        "    \"and I'd like recommendations that include scenic runs by the river, museums, and quiet dinner spots.\"\n",
        ")\n",
        "\n",
        "res = u.add(rich_message, budget=\"standard\")\n",
        "pack = res.get(\"pack\") or {}\n",
        "ok_budget = (pack.get(\"used_tokens\", 0) <= pack.get(\"hard_cap_tokens\", 10**9))\n",
        "print(\"Stored. request_id=\", res.get(\"request_id\"))\n",
        "print(\"Pack:\", pack)\n",
        "print(\"‚úÖ Memories stored and within budget\" if ok_budget else \"‚ö†Ô∏è Stored but over budget cap\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VuY-otofgCCK"
      },
      "outputs": [],
      "source": [
        "# Step 2: Verify memories exist (facts/events)\n",
        "page = client.get_all(entity_id=entity_id, limit=10)\n",
        "items = page.get(\"items\", [])\n",
        "print(\"Fetched\", len(items), \"items\")\n",
        "for m in items[:6]:\n",
        "    print(\"-\", m.get(\"type\"), \"::\", m.get(\"text\"))\n",
        "print(\"‚úÖ Memories listed\" if len(items) > 0 else \"‚ö†Ô∏è No memories returned\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzZ9QNTAgCCK"
      },
      "outputs": [],
      "source": [
        "# Step 3: Retrieve context for a new message\n",
        "query = \"Looking for a quiet dinner near a scenic running route in Lyon; any museum picks?\"\n",
        "res = client.search(query, entity_id=entity_id, top_k=16, include_scores=True)\n",
        "matches = res.get(\"matches\", [])\n",
        "print(\"Matches:\", len(matches))\n",
        "for m in matches[:6]:\n",
        "    print(f\"- {m.get('text')} (score={round(m.get('score', 0),3)})\")\n",
        "print(\"‚úÖ Retrieval returned matches\" if len(matches) > 0 else \"‚ö†Ô∏è No matches yet (indexing may take a few seconds)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bo5qk4CQgCCK"
      },
      "source": [
        "### Next steps\n",
        "- Try adding another turn (preferences, places, ratings)\n",
        "- Use the Agent helper for end-to-end chat with citations\n",
        "- Explore the graph view in the dashboard to see entities and relationships emerge\n",
        "\n",
        "![Memory Graph from Dashboard](https://raw.githubusercontent.com/alex-n-a/flumes-ai-sdk/main/learning/assets/onboarding-graph.png)\n",
        "\n",
        "![Filtered Memory Graph from Dashboard](https://raw.githubusercontent.com/alex-n-a/flumes-ai-sdk/main/learning/assets/filtered-onboarding-graph.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZaywt8ygCCK"
      },
      "source": [
        "## Advanced: Retrieval weights, budgeting, and presets\n",
        "\n",
        "Flumes retrieval combines semantic, keyword (BM25), and graph signals. You control it with a simple `retrieval` object:\n",
        "\n",
        "- `preset`: one of `balanced | factual | recent | graphy`\n",
        "- Or `weights`: `{ semantic, bm25, graph_prior, recency_decay, confidence }` (server renormalizes; flags indicate if adjusted)\n",
        "- `top_k`: number of candidates to return (default 16)\n",
        "\n",
        "Budgeting keeps cost predictable:\n",
        "- `budget = \"light\" | \"standard\" | \"heavy\"` ‚Üí max_context_tokens of ~400 / 1200 / 2400 (hard caps applied)\n",
        "- Each `add()` returns `pack = { target_tokens, hard_cap_tokens, used_tokens, dropped[] }`\n",
        "\n",
        "You can pass these knobs per call or set them as defaults on the client.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AMsOjl-GgCCK"
      },
      "outputs": [],
      "source": [
        "# Try custom retrieval weights and a different budget\n",
        "query = \"Quiet dinner near scenic runs and impressionist museums during my trip\"\n",
        "res = client.search(\n",
        "    query,\n",
        "    entity_id=entity_id,\n",
        "    top_k=16,\n",
        "    weights={\"semantic\": 0.6, \"bm25\": 0.3, \"graph_prior\": 0.1},\n",
        "    include_scores=True,\n",
        ")\n",
        "ms = res.get(\"matches\", [])\n",
        "print(\"Top 5 with custom weights:\")\n",
        "for m in ms[:5]:\n",
        "    print(f\"- {m.get('text')} (score={round(m.get('score', 0),3)})\")\n",
        "print(\"‚úÖ Weighted retrieval returned matches\" if len(ms) > 0 else \"‚ö†Ô∏è No matches\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4dtWGxDZgCCK"
      },
      "source": [
        "## Optional: Agent SDK (end-to-end chat)\n",
        "If you have an OpenAI key configured, you can run a short chat with grounded context. This uses the same `add()` assemble call under the hood.\n",
        "\n",
        "Before running the next cells, ensure `OPENAI_API_KEY` is set in your environment.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0zIKT_mZgCCL"
      },
      "outputs": [],
      "source": [
        "# Provide your OpenAI API key explicitly\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\", \"your-openai-key\")\n",
        "if OPENAI_API_KEY == \"your-openai-key\":\n",
        "    raise RuntimeError(\"Set OPENAI_API_KEY or paste your key in OPENAI_API_KEY before running the Agent example.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TIuUZVrMgCCL"
      },
      "outputs": [],
      "source": [
        "\n",
        "from flumes import Agent\n",
        "agent = Agent(\n",
        "    agent_id=\"onboarding-bot\",\n",
        "    entity_id=entity_id,\n",
        "    memory_client=client,\n",
        "    openai_api_key=OPENAI_API_KEY,\n",
        ")\n",
        "answer = agent.chat(\"Plan my trip.\")\n",
        "print(answer)\n",
        "print(\"‚úÖ Agent produced a grounded answer\" if answer else \"‚ö†Ô∏è Agent returned empty text\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GrQTAlA-gCCL"
      },
      "source": [
        "## Wrap‚Äëup and next steps\n",
        "You're done! You installed the SDK, initialized a client, added a dense message, verified stored memories, and retrieved context.\n",
        "\n",
        "Where to go next:\n",
        "- View your memory graph in the dashboard (entities, facts, relationships)\n",
        "- Read the API reference and concepts (retrieval presets, budgeting, policies)\n",
        "- Explore SDK examples (Python, Node)\n",
        "\n",
        "Replace these with your links:\n",
        "- Dashboard: app.flumes.ai/graph-memory\n",
        "- Docs: https://docs.flumes.ai/api-reference/system/liveness-&-readiness\n",
        "- SDK repos: https://github.com/alex-n-a/flumes-ai-sdk\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}